###**线性模型**

 **1.**给定由d个属性描述的**x** ={$x_1$;$x_2$;...;$x_d$},其中$x_i$是**x**在第i个属性上的取值，线性模型试图通过学得一个通过属性得线性  组合来进行预测的函数。
 - 线性模型是的基本形式是
	                   $$f(x)=w_1x_1+w_2x_2+..+w_ix_i+b$$
	                   
 - 一般用向量形式写成
					   $$f(x)=w^Tx +b$$
				
**2.**给的数据集$D = \{(x_1;y_1),..,(x_i;y_i)\}$, 线性回归试图学得一个线性模型以尽可能得预测输出标志。考虑单一属性$x_i$,线性回归试图学得
$$f(x_i)=wx_i+b，使得f(x_i)近似于y_i$$
度量$f(x)$与$y$之间得差别,  回归任务中最常用得性能度量是**均方误差**：
$$E(f;D)=\frac{1}{m}\sum_{i=1}^m(f(x_i)-y_i)^2$$
在**均方误差最小化时，取w，b**：
$$(w,b)=arg_{(w,b)}min\sum_{i=1}^m(f(x_i)-y_i)^2=arg_{(w,b)}min\sum_{i=1}^m(y_i-wx_i-b)^2$$
均方误差对应了常用得欧式距离，基于均方误差最小化来进行模型求解得方法称为**“最小二乘法”**。在线性回归中，最小二乘法试图找到一条直线，使得所有得样本到直线上得**欧式距离最短**。
对$w和b$分别求偏导，当偏导为0时，可得$w和b$的最优解的闭式解：
$$w=\frac{\sum_{i=1}^my_i(x_i-\bar x)}{(\sum_{x=1}^mx_i^2) -\frac{1}{m}(\sum_{i=1}^mx_i)^2 }$$
$$b=\frac{1}{m}\sum_{i=1}^m(y_i-wx_i)$$
 
 - 若数据集D有d个属性描述，则有
 $$f(x_i)=w^T+b$$
 称为**多元线性回归**。
以后补充
 

	 
